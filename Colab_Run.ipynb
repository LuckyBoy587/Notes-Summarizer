{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6988ea33",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/LuckyBoy587/Notes-Summarizer/blob/master/Colab_Run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Notes Summarizer on Colab\n",
    "\n",
    "This notebook allows you to easily run the Notes Summarizer on Google Colab. It will clone the latest code from GitHub, install dependencies, and process a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f1127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Clone repository, install dependencies, and download NLTK data\n",
    "!git clone https://github.com/LuckyBoy587/Notes-Summarizer.git\n",
    "%cd Notes-Summarizer\n",
    "!pip install -r requirements.txt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e59759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from config import model, tokenizer, device\n",
    "from text_processing import split_into_topics\n",
    "from paraphrasing import paraphrase_chunks\n",
    "from pdf_extraction import extract_topics_from_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload PDF\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "pdf_filename = list(uploaded.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc39c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PDF: Extract topics, split, paraphrase, and save (use fast sampling for extraction)\n",
    "# fast=True uses a small set of sampled pages to estimate font-size thresholds which speeds up large PDFs\n",
    "extracted_text = extract_topics_from_pdf(pdf_filename, fast=True, sample_pages=3)\n",
    "topics = split_into_topics(extracted_text)\n",
    "\n",
    "output_content = \"\"\n",
    "for topic, chunks in topics.items():\n",
    "    bullets = paraphrase_chunks(chunks, model, tokenizer, device)\n",
    "    output_content += f\"\\n## {topic}\\n\"\n",
    "    output_content += \"\\n\".join([f\"â€¢ {b}\" for b in bullets]) + \"\\n\"\n",
    "\n",
    "output_filename = pdf_filename.replace('.pdf', '_paraphrased.txt')\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_content)\n",
    "\n",
    "print(f\"Output saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495cf090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the result\n",
    "files.download(output_filename)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
